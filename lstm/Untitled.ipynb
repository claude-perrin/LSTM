{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff157fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# My code\n",
    "from main import my_build_model, my_train\n",
    "\n",
    "# HyperParameters:\n",
    "embed_dim = 14\n",
    "lstm_out = 1\n",
    "batch_size = 32\n",
    "num_words = 2500\n",
    "# =============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99981a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing dataset\n",
    "\n",
    "def convert(x):\n",
    "    \"\"\"\n",
    "    Coverting JSON to pandas dataframe\n",
    "\n",
    "    \"\"\"    \n",
    "    ob = json.loads(x)\n",
    "    for k, v in ob.items():\n",
    "        if isinstance(v, list):\n",
    "            ob[k] = ','.join(v)\n",
    "        elif isinstance(v, dict):\n",
    "            for kk, vv in v.items():\n",
    "                ob['%s_%s' % (k, kk)] = vv\n",
    "            del ob[k]\n",
    "    return ob\n",
    "\n",
    "\n",
    "\n",
    "def filter_data(data):\n",
    "    \"\"\"\n",
    "    Converting into pandas dataframe and filtering only text and ratings given by the users\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame([convert(line) for line in data])\n",
    "    df.drop(columns=df.columns.difference(['text','stars']),inplace=True)\n",
    "    df.loc[:, (\"sentiment\")] = 0\n",
    "    \n",
    "\n",
    "#     #I have considered a rating above 3 as positive and less than or equal to 3 as negative.\n",
    "    df.loc[:,'sentiment']=['pos' if (x>3) else 'neg' for x in df.loc[:, 'stars']]\n",
    "    df.loc[:,'text'] = df.loc[:,'text'].apply(lambda x: x.lower())\n",
    "    df.loc[:,'text'] = df.loc[:,'text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "    for idx,row in df.iterrows():\n",
    "        df.loc[:,'text']= [x for x in df.loc[:,'text']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "538f5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Buidling the LSTM network using Keras\n",
    "\n",
    "def build_model(X):\n",
    "    model = Sequential()\n",
    "    print(X.shape[1])\n",
    "    model.add(Embedding(num_words, embed_dim,input_length = X.shape[1]))\n",
    "    model.add(LSTM(lstm_out))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model):\n",
    "\n",
    "    Y = pd.get_dummies(data['sentiment']).values\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.20, random_state = 36)\n",
    "\n",
    "    #Here we train the Network.\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=10,  verbose=5)\n",
    "\n",
    "    # Measuring score and accuracy on validation set\n",
    "    score,acc = model.evaluate(X_valid, Y_valid, verbose=2, batch_size=batch_size)\n",
    "    print(\"Logloss score: %.2f\" % (score))\n",
    "    print(\"Validation set Accuracy: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3363f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = 'review_mockup.json'\n",
    "with open(json_filename,'rb') as f:\n",
    "    data = f.readlines()\n",
    "data = filter_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7c5b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   9   6 324 185   2   4 131 289 109 293   9   4   6  63]\n",
      " [583   2 583 119   2  84  67  60  74  97   4 667 388 554  67  46  15]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = num_words, split=' ')\n",
    "tokenizer.fit_on_texts(data.loc[:,'text'].values)\n",
    "# #print(tokenizer.word_index)  # To see the dicstionary\n",
    "# X = tokenizer.texts_to_sequences(data.loc[:,'text'].values)\n",
    "# X = pad_sequences(X)\n",
    "# print((X[0]))\n",
    "\n",
    "test=tokenizer.texts_to_sequences([\"It was quite awesome and I know why people enjoy it I was also\", \"Yes, and Yes again and even more really nice than I expected keep doing more like this\"])\n",
    "test = pad_sequences(test)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31c31e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "[[  0   0   0   9   6 324 185   2   4 131 289 109 293   9   4   6  63]\n",
      " [583   2 583 119   2  84  67  60  74  97   4 667 388 554  67  46  15]]\n",
      "<keras.layers.core.embedding.Embedding object at 0x28e05d270>\n",
      "<keras.layers.rnn.lstm.LSTM object at 0x28c357280>\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x105e0da50>\n",
      "<keras.layers.core.dense.Dense object at 0x17c0e4730>\n",
      "[<tf.Variable 'lstm_31/lstm_cell_31/kernel:0' shape=(14, 4) dtype=float32, numpy=\n",
      "array([[-0.21732277,  0.3768264 ,  0.21355677, -0.56960326],\n",
      "       [ 0.3319708 , -0.12626523, -0.23944962,  0.5683081 ],\n",
      "       [ 0.5289732 ,  0.06493247, -0.38721386, -0.42209256],\n",
      "       [-0.424585  ,  0.04019493,  0.08187032,  0.01120645],\n",
      "       [-0.02018017, -0.39744174, -0.14973843, -0.00911444],\n",
      "       [ 0.0773834 , -0.33750904, -0.36691898,  0.5760077 ],\n",
      "       [-0.15068161, -0.13939714,  0.31443846,  0.21029115],\n",
      "       [-0.1162456 ,  0.3280173 ,  0.2064622 ,  0.2701525 ],\n",
      "       [ 0.06009567, -0.4509277 ,  0.17181736,  0.5647385 ],\n",
      "       [ 0.36992615,  0.23637134,  0.52869403, -0.5508219 ],\n",
      "       [ 0.5034342 ,  0.17473668, -0.21173069, -0.57606214],\n",
      "       [ 0.4863819 , -0.13593066,  0.31461012,  0.47936463],\n",
      "       [ 0.08673334,  0.33872217, -0.0820111 , -0.35658348],\n",
      "       [ 0.28319097, -0.09512416,  0.36644548, -0.34505782]],\n",
      "      dtype=float32)>, <tf.Variable 'lstm_31/lstm_cell_31/recurrent_kernel:0' shape=(1, 4) dtype=float32, numpy=\n",
      "array([[-0.15549159, -0.06155382,  0.32753024, -0.9299233 ]],\n",
      "      dtype=float32)>, <tf.Variable 'lstm_31/lstm_cell_31/bias:0' shape=(4,) dtype=float32, numpy=array([0., 1., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "model = build_model(test)\n",
    "print(test)\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "print(model.layers[1].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb6df3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train(model)\n",
      "Cell \u001B[0;32mIn[4], line 16\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mtrain\u001B[39m(model):\n\u001B[0;32m---> 16\u001B[0m     Y \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39mget_dummies(data[\u001B[39m'\u001B[39m\u001B[39msentiment\u001B[39m\u001B[39m'\u001B[39m])\u001B[39m.\u001B[39mvalues\n\u001B[1;32m     17\u001B[0m     X_train, X_valid, Y_train, Y_valid \u001B[39m=\u001B[39m train_test_split(X,Y, test_size \u001B[39m=\u001B[39m \u001B[39m0.20\u001B[39m, random_state \u001B[39m=\u001B[39m \u001B[39m36\u001B[39m)\n\u001B[1;32m     19\u001B[0m     \u001B[39m#Here we train the Network.\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273667ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(test) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "print(y_prob)\n",
    "print(y_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334e6052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " ...\n",
      " [ True False]\n",
      " [False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "############### My code\n",
    "model = my_build_model(X, hidden_size=lstm_out, input_size = len(X[0]))\n",
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53508079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  700    3 1417    2  135\n",
      " 2259    6   32   14  746   11  878   17   34   95  598  521    3  181\n",
      "  377    5  184    1  545  500    2 1417  190 1787    8    5 1046   10\n",
      "  344    4  153    1  878  693  225    6  166  363 1621  187    6   29\n",
      "  488    7   29  717   11    1  759    2   52  932    2   40    2 1973\n",
      "    6   63   31  318   52   51]\n",
      "(300, 1)\n",
      "(1, 300)\n",
      "finish\n",
      "(944, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mlen\u001B[39m(X[\u001B[39m0\u001B[39m]))\n\u001B[0;32m----> 2\u001B[0m my_train(model, X, Y, lstm_out, \u001B[39mlen\u001B[39;49m(X[\u001B[39m0\u001B[39;49m]))\n",
      "File \u001B[0;32m~/polsl/BIAI/lstm/main.py:51\u001B[0m, in \u001B[0;36mmy_train\u001B[0;34m(lstm, X, Y, hidden_size, input_size)\u001B[0m\n\u001B[1;32m     49\u001B[0m c \u001B[39m=\u001B[39m np\u001B[39m.\u001B[39mzeros((hidden_size, \u001B[39m1\u001B[39m))\n\u001B[1;32m     50\u001B[0m \u001B[39m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m forward_pass \u001B[39m=\u001B[39m lstm\u001B[39m.\u001B[39;49mforward(inputs, h, c)\n\u001B[1;32m     53\u001B[0m \u001B[39m# Backward pass\u001B[39;00m\n\u001B[1;32m     54\u001B[0m loss \u001B[39m=\u001B[39m lstm\u001B[39m.\u001B[39mcalculate_loss(forward_pass[\u001B[39m\"\u001B[39m\u001B[39mresult\u001B[39m\u001B[39m\"\u001B[39m], targets)\n",
      "File \u001B[0;32m~/polsl/BIAI/lstm/lstm.py:167\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, inputs, stm_prev, ltm_prev)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39m\"\u001B[39m\u001B[39mfinish\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m    166\u001B[0m \u001B[39mprint\u001B[39m(v\u001B[39m.\u001B[39mshape)\n\u001B[0;32m--> 167\u001B[0m exit(\u001B[39m1\u001B[39m)\n\u001B[1;32m    169\u001B[0m \u001B[39m# Calculate softmax\u001B[39;00m\n\u001B[1;32m    170\u001B[0m result \u001B[39m=\u001B[39m softmax(v)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(X[0]))\n",
    "my_train(model, X, Y, lstm_out, len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af261c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
